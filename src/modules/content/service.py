"""
å†…å®¹ç”ŸæˆæœåŠ¡
Content Generation Service

æä¾›AIé©±åŠ¨çš„å•†å“æ ‡é¢˜å’Œæè¿°ç”ŸæˆåŠŸèƒ½
"""

import os
import time
from hashlib import sha1
from typing import Any

from openai import APIError, APITimeoutError, AsyncOpenAI, OpenAI

from src.core.compliance import get_compliance_guard
from src.core.config import get_config
from src.core.logger import get_logger

PROVIDER_KEY_MAP = {
    "openai": "OPENAI_API_KEY",
    "deepseek": "DEEPSEEK_API_KEY",
    "aliyun_bailian": "DASHSCOPE_API_KEY",
    "volcengine_ark": "ARK_API_KEY",
    "minimax": "MINIMAX_API_KEY",
    "zhipu": "ZHIPU_API_KEY",
}

PROVIDER_BASE_URL_MAP = {
    "openai": "https://api.openai.com/v1",
    "deepseek": "https://api.deepseek.com/v1",
    "aliyun_bailian": "https://dashscope.aliyuncs.com/compatible-mode/v1",
    "volcengine_ark": "https://ark.cn-beijing.volces.com/api/v3",
    "minimax": "https://api.minimaxi.com/v1",
    "zhipu": "https://open.bigmodel.cn/api/paas/v4",
}

PROVIDER_MODEL_MAP = {
    "openai": "gpt-4o-mini",
    "deepseek": "deepseek-chat",
    "aliyun_bailian": "qwen-plus-latest",
    "volcengine_ark": "doubao-1.5-pro-32k-250115",
    "minimax": "MiniMax-Text-01",
    "zhipu": "glm-4-plus",
}


class ContentService:
    """
    å†…å®¹ç”ŸæˆæœåŠ¡

    é›†æˆå¤§è¯­è¨€æ¨¡å‹ï¼Œç”Ÿæˆé«˜è´¨é‡çš„å•†å“æ ‡é¢˜å’Œæè¿°æ–‡æ¡ˆ
    """

    def __init__(self, config: dict | None = None):
        """
        åˆå§‹åŒ–å†…å®¹ç”ŸæˆæœåŠ¡

        Args:
            config: é…ç½®å­—å…¸
        """
        self.config = config or get_config().ai
        self.logger = get_logger()
        self.compliance = get_compliance_guard()

        self.provider = str(self.config.get("provider") or os.getenv("AI_PROVIDER") or "deepseek").lower()
        provider_key_env = PROVIDER_KEY_MAP.get(self.provider, "")

        provider_scoped_api_key = os.getenv(provider_key_env) if provider_key_env else None
        # ä¼˜å…ˆè¯»å–æ˜¾å¼ AI_API_KEYï¼›å¦åˆ™æŒ‰ provider è¯»å–å¯¹åº”ç¯å¢ƒå˜é‡ï¼Œé¿å…è·¨ä¾›åº”å•†è¯¯ç”¨å¯†é’¥ã€‚
        resolved_api_key = self._normalize_config_value(os.getenv("AI_API_KEY") or provider_scoped_api_key)
        resolved_base_url = self._normalize_config_value(
            os.getenv("AI_BASE_URL")
            or PROVIDER_BASE_URL_MAP.get(self.provider)
            or os.getenv("OPENAI_BASE_URL")
            or os.getenv("DEEPSEEK_BASE_URL")
        )
        resolved_model = self._normalize_config_value(
            os.getenv("AI_MODEL") or PROVIDER_MODEL_MAP.get(self.provider, "deepseek-chat")
        )

        configured_api_key = self._normalize_config_value(self.config.get("api_key"))
        configured_base_url = self._normalize_config_value(self.config.get("base_url"))
        configured_model = self._normalize_config_value(self.config.get("model"))

        self.api_key = configured_api_key or resolved_api_key
        self.base_url = configured_base_url or resolved_base_url
        self.model = configured_model or resolved_model or "deepseek-chat"
        self.temperature = self.config.get("temperature", 0.7)
        self.max_tokens = self.config.get("max_tokens", 1000)
        self.timeout = self.config.get("timeout", 30)
        self.fallback_enabled = self.config.get("fallback_enabled", True)
        self.fallback_model = self.config.get("fallback_model", "gpt-3.5-turbo")
        self.usage_mode = str(self.config.get("usage_mode", "minimal")).lower()
        self.max_calls_per_run = int(self.config.get("max_calls_per_run", 20))
        self.cache_ttl_seconds = int(self.config.get("cache_ttl_seconds", 900))
        self.cache_max_entries = int(self.config.get("cache_max_entries", 200))
        self.task_switches = self.config.get("task_switches", {})

        self.client: OpenAI | None = None
        self.async_client: AsyncOpenAI | None = None
        self._response_cache: dict[str, tuple[float, str]] = {}
        self._ai_calls = 0
        self._cache_hits = 0
        self._estimated_prompt_tokens = 0
        self._estimated_response_tokens = 0

        self._init_client()

    @staticmethod
    def _normalize_config_value(value: Any) -> str | None:
        raw = str(value or "").strip()
        if not raw:
            return None
        if raw.startswith("${") and raw.endswith("}"):
            return None
        return raw

    def _init_client(self) -> None:
        """åˆå§‹åŒ–AIå®¢æˆ·ç«¯"""
        if self.api_key:
            try:
                self.client = OpenAI(api_key=self.api_key, base_url=self.base_url)
                self.async_client = AsyncOpenAI(api_key=self.api_key, base_url=self.base_url)
                self.logger.success("AI client initialized successfully")
            except Exception as e:
                self.logger.error(f"Failed to initialize AI client: {e}")
                self.client = None
        else:
            self.logger.warning("AI API Key not found. Content generation will use templates.")

    def _call_ai(self, prompt: str, max_tokens: int | None = None, task: str = "generic") -> str | None:
        """
        è°ƒç”¨AIç”Ÿæˆå†…å®¹

        Args:
            prompt: æç¤ºè¯
            max_tokens: æœ€å¤§tokenæ•°

        Returns:
            ç”Ÿæˆçš„å†…å®¹ï¼Œå¤±è´¥è¿”å›None
        """
        if not self.client:
            return None

        if not self._should_call_ai(task, prompt):
            return None

        cached = self._cache_get(prompt, task)
        if cached is not None:
            self._cache_hits += 1
            return cached

        if self._ai_calls >= self.max_calls_per_run:
            self.logger.warning(f"AI call budget exceeded for this run: {self.max_calls_per_run}")
            return None

        try:
            self._ai_calls += 1
            estimated_prompt_tokens = max(1, len(prompt) // 4)
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[{"role": "user", "content": prompt}],
                temperature=self.temperature,
                max_tokens=max_tokens or self.max_tokens,
                timeout=self.timeout,
            )
            content = response.choices[0].message.content.strip()
            self._estimated_prompt_tokens += estimated_prompt_tokens
            self._estimated_response_tokens += max(1, len(content) // 4)
            self._cache_set(prompt, task, content)
            return content
        except APITimeoutError as e:
            self.logger.error(f"AI call timeout after {self.timeout}s: {e}")
            return None
        except APIError as e:
            self.logger.error(f"AI API error: {e}")
            return None
        except Exception as e:
            self.logger.error(f"Unexpected AI call error: {e}")
            return None

    def _should_call_ai(self, task: str, prompt: str) -> bool:
        if self.usage_mode == "always":
            return True
        enabled = bool(self.task_switches.get(task, False))
        if self.usage_mode == "minimal":
            return enabled
        if self.usage_mode == "auto":
            return enabled or len(prompt) > 320
        return enabled

    def _cache_key(self, prompt: str, task: str) -> str:
        return sha1(f"{task}:{prompt}".encode()).hexdigest()

    def _cache_get(self, prompt: str, task: str) -> str | None:
        key = self._cache_key(prompt, task)
        data = self._response_cache.get(key)
        if not data:
            return None
        expires_at, content = data
        if expires_at < time.time():
            self._response_cache.pop(key, None)
            return None
        return content

    def _cache_set(self, prompt: str, task: str, content: str) -> None:
        if self.cache_max_entries <= 0:
            return
        if len(self._response_cache) >= self.cache_max_entries:
            oldest_key = next(iter(self._response_cache.keys()))
            self._response_cache.pop(oldest_key, None)
        key = self._cache_key(prompt, task)
        self._response_cache[key] = (time.time() + self.cache_ttl_seconds, content)

    def get_ai_cost_stats(self) -> dict[str, Any]:
        total_calls = self._ai_calls
        total_tokens = self._estimated_prompt_tokens + self._estimated_response_tokens
        avg_tokens = round(total_tokens / total_calls, 2) if total_calls else 0.0
        monthly_estimated_cost_cny = round((total_tokens / 1000) * 0.02, 4)
        return {
            "usage_mode": self.usage_mode,
            "max_calls_per_run": self.max_calls_per_run,
            "ai_calls": total_calls,
            "cache_hits": self._cache_hits,
            "cache_hit_rate": round((self._cache_hits / (self._cache_hits + total_calls)), 4)
            if (self._cache_hits + total_calls)
            else 0.0,
            "estimated_prompt_tokens": self._estimated_prompt_tokens,
            "estimated_response_tokens": self._estimated_response_tokens,
            "avg_tokens_per_call": avg_tokens,
            "estimated_monthly_cost_cny": monthly_estimated_cost_cny,
        }

    def generate_title(self, product_name: str, features: list[str], category: str = "General") -> str:
        """
        ç”Ÿæˆé—²é±¼å•†å“æ ‡é¢˜

        Args:
            product_name: å•†å“åç§°
            features: å•†å“ç‰¹ç‚¹åˆ—è¡¨
            category: å•†å“åˆ†ç±»

        Returns:
            ç”Ÿæˆçš„æ ‡é¢˜
        """
        if not self.client:
            return self._default_title(product_name, features)

        keywords = self._get_category_keywords(category)
        prompt = f"""
        è¯·ä¸ºé—²é±¼ï¼ˆäºŒæ‰‹äº¤æ˜“å¹³å°ï¼‰å•†å“ç”Ÿæˆä¸€ä¸ªå¸å¼•äººçš„æ ‡é¢˜ã€‚

        å•†å“åç§°: {product_name}
        å•†å“ç‰¹ç‚¹: {", ".join(features)}
        å•†å“åˆ†ç±»: {category}
        æ¨èå…³é”®è¯: {", ".join(keywords[:5])}

        è¦æ±‚:
        1. 15-25å­—ä»¥å†…
        2. åŒ…å«1-2ä¸ªçƒ­æœå…³é”®è¯æé«˜æœç´¢æ›å…‰
        3. çªå‡ºå•†å“å–ç‚¹æˆ–æ€§ä»·æ¯”
        4. çœŸå®æ„Ÿå¼ºï¼Œä¸è¦è¿‡äºå¹¿å‘Šè…”
        5. å¯ä»¥ä½¿ç”¨ç¬¦å·å¢åŠ å¸å¼•åŠ›ï¼Œå¦‚ã€ã€‘ã€ğŸ”¥ã€ğŸ’°ç­‰
        """
        result = self._call_ai(prompt, max_tokens=60, task="title")

        if result and len(result) <= 30:
            return result

        return self._default_title(product_name, features)

    def _default_title(self, product_name: str, features: list[str]) -> str:
        """ç”Ÿæˆé»˜è®¤æ ‡é¢˜"""
        feature_str = " ".join(features[:2]) if features else ""
        return f"ã€è½¬å–ã€‘{product_name} {feature_str}".strip()[:25]

    def _get_category_keywords(self, category: str) -> list[str]:
        """è·å–åˆ†ç±»çƒ­æœå…³é”®è¯"""
        keywords = {
            "æ•°ç æ‰‹æœº": ["è‡ªç”¨", "é—²ç½®", "æ­£å“", "å›½è¡Œ", "åŸè£…", "95æ–°", "ä¾¿å®œå‡º"],
            "ç”µè„‘åŠå…¬": ["åŠå…¬", "æ¸¸æˆ", "é«˜æ€§èƒ½", "ä½ä»·", "æˆè‰²æ–°"],
            "å®¶ç”µ": ["å®¶ç”¨", "é—²ç½®", "å‡ ä¹å…¨æ–°", "ä¿ä¿®æœŸå†…"],
            "æœé¥°é‹åŒ…": ["ä¸“æŸœ", "æ­£å“", "å…¨æ–°", "é—²ç½®", "ç™½èœä»·"],
            "ç¾å¦†æŠ¤è‚¤": ["æ­£å“", "ä¿çœŸ", "é—²ç½®", "ä¸´æœŸç‰¹æƒ "],
            "å®¶å±…": ["äºŒæ‰‹", "æ¬å®¶æ€¥å‡º", "å‡ ä¹æ²¡ç”¨è¿‡"],
            "General": ["é—²ç½®", "ä¾¿å®œå‡º", "è‡ªç”¨", "è½¬è®©"],
        }
        return keywords.get(category, keywords["General"])

    def _get_sample_keywords(self, category: str) -> list[str]:
        """å…¼å®¹æ—§æ¥å£ï¼šè¿”å›åˆ†ç±»å…³é”®è¯æ ·æœ¬"""
        return self._get_category_keywords(category)

    def generate_description(
        self, product_name: str, condition: str, reason: str, tags: list[str], extra_info: str | None = None
    ) -> str:
        """
        ç”Ÿæˆé—²é±¼å•†å“æè¿°æ–‡æ¡ˆ

        Args:
            product_name: å•†å“åç§°
            condition: æˆè‰²æè¿°
            reason: è½¬æ‰‹åŸå› 
            tags: æ ‡ç­¾åˆ—è¡¨
            extra_info: é¢å¤–ä¿¡æ¯

        Returns:
            ç”Ÿæˆçš„æè¿°æ–‡æ¡ˆ
        """
        if not self.client:
            return self._default_description(product_name, condition, reason, tags)

        prompt = f"""
        è¯·å†™ä¸€æ®µé—²é±¼å•†å“çš„è¯¦ç»†æè¿°æ–‡æ¡ˆã€‚

        å•†å“åç§°: {product_name}
        å•†å“æˆè‰²: {condition}
        è½¬æ‰‹åŸå› : {reason}
        æ ‡ç­¾: {", ".join(tags)}
        é¢å¤–ä¿¡æ¯: {extra_info or "æ— "}

        è¦æ±‚:
        1. è¯­æ°”äº²åˆ‡è‡ªç„¶ï¼Œè¥é€ çœŸå®ä¸ªäººå–å®¶æ„Ÿ
        2. å¼€å¤´å¼•å…¥ï¼Œè¯´æ˜å•†å“æ¥æºæˆ–ç‰¹ç‚¹
        3. ä¸­é—´è¯¦ç»†æè¿°æˆè‰²ã€ä½¿ç”¨æƒ…å†µã€ç‘•ç–µï¼ˆå¦‚æœ‰ï¼‰
        4. ç»“å°¾è¯´æ˜äº¤æ˜“æ–¹å¼ï¼Œå¼•å¯¼ç§èŠ
        5. 100-200å­—ä¸ºå®œ
        6. ä¸è¦ä½¿ç”¨è¿‡å¤šemojiï¼Œé€‚åº¦ä½¿ç”¨
        """
        result = self._call_ai(prompt, max_tokens=300, task="description")

        if result and len(result) >= 50:
            return result

        return self._default_description(product_name, condition, reason, tags)

    def _default_description(self, product_name: str, condition: str, reason: str, tags: list[str]) -> str:
        """ç”Ÿæˆé»˜è®¤æè¿°"""
        return f"""å‡ºé—²ç½® {product_name}ï¼Œæˆè‰²{condition}ã€‚

{reason}ï¼Œæ‰€ä»¥è½¬è®©ã€‚

å•†å“è¯¦æƒ…ï¼š
- æˆè‰²ï¼š{condition}
- äº¤æ˜“è¯´æ˜ï¼šèµ°é—²é±¼ï¼Œè¯šå¿ƒè¦çš„ç§èŠ"""

    def generate_listing_content(self, product_info: dict[str, Any]) -> dict[str, Any]:
        """
        ç”Ÿæˆå®Œæ•´å•†å“å‘å¸ƒå†…å®¹

        Args:
            product_info: å•†å“ä¿¡æ¯å­—å…¸

        Returns:
            åŒ…å«titleå’Œdescriptionçš„å­—å…¸
        """
        product_name = product_info.get("name", "å•†å“")
        features = product_info.get("features", [])
        category = product_info.get("category", "General")
        condition = product_info.get("condition", "95æ–°")
        reason = product_info.get("reason", "ç”¨ä¸ä¸Š")
        tags = product_info.get("tags", [])
        extra_info = product_info.get("extra_info")

        title = self.generate_title(product_name, features, category)
        description = self.generate_description(product_name, condition, reason, tags, extra_info)
        review = self.review_before_publish(title, description)
        return {"title": title, "description": description, "compliance": review}

    def review_before_publish(self, title: str, description: str) -> dict[str, Any]:
        """
        å‘å¸ƒå‰æ–‡æœ¬å®¡æŸ¥

        Returns:
            {"allowed": bool, "hits": list[str], "message": str}
        """
        decision = self.compliance.evaluate_content(title, description)
        return {
            "allowed": decision["allowed"],
            "blocked": decision["blocked"],
            "warn": decision["warn"],
            "hits": decision["hits"],
            "message": decision["message"],
            "mode": self.compliance.mode,
        }

    def optimize_title(self, current_title: str, category: str = "General") -> str:
        """
        ä¼˜åŒ–ç°æœ‰æ ‡é¢˜

        Args:
            current_title: å½“å‰æ ‡é¢˜
            category: å•†å“åˆ†ç±»

        Returns:
            ä¼˜åŒ–åçš„æ ‡é¢˜
        """
        keywords = self._get_category_keywords(category)

        prompt = f"""
        è¯·ä¼˜åŒ–ä»¥ä¸‹é—²é±¼å•†å“æ ‡é¢˜ï¼Œæé«˜æœç´¢æ›å…‰å’Œå¸å¼•åŠ›ã€‚

        å½“å‰æ ‡é¢˜: {current_title}
        åˆ†ç±»: {category}
        æ¨èå…³é”®è¯: {", ".join(keywords)}

        è¦æ±‚:
        1. ä¿æŒæ ‡é¢˜æ ¸å¿ƒä¿¡æ¯ä¸å˜
        2. é€‚å½“æ·»åŠ çƒ­æœå…³é”®è¯
        3. 15-25å­—ä»¥å†…
        4. ä¸è¦è¿‡äºå¹¿å‘ŠåŒ–

        è¯·ç›´æ¥è¿”å›ä¼˜åŒ–åçš„æ ‡é¢˜ï¼Œä¸éœ€è¦é¢å¤–è¯´æ˜ã€‚
        """

        result = self._call_ai(prompt, max_tokens=50, task="optimize_title")

        if result and len(result) >= 5 and len(result) <= 30:
            return result

        return current_title

    def generate_seo_keywords(self, product_name: str, category: str) -> list[str]:
        """
        ç”ŸæˆSEOä¼˜åŒ–å…³é”®è¯

        Args:
            product_name: å•†å“åç§°
            category: å•†å“åˆ†ç±»

        Returns:
            å…³é”®è¯åˆ—è¡¨
        """
        prompt = f"""
        ä¸ºé—²é±¼å•†å“ç”ŸæˆSEOå…³é”®è¯ã€‚

        å•†å“: {product_name}
        åˆ†ç±»: {category}

        è¯·ç”Ÿæˆ5-8ä¸ªç›¸å…³çƒ­æœå…³é”®è¯ï¼ŒæŒ‰çƒ­åº¦æ’åºã€‚
        åªéœ€è¦è¿”å›å…³é”®è¯åˆ—è¡¨ï¼Œç”¨é€—å·åˆ†éš”ã€‚
        """

        result = self._call_ai(prompt, max_tokens=100, task="seo_keywords")

        if result:
            keywords = [k.strip() for k in result.split(",")]
            return [k for k in keywords if k][:8]

        return self._get_category_keywords(category)
